{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T09:01:45.676295Z","iopub.execute_input":"2024-07-05T09:01:45.677153Z","iopub.status.idle":"2024-07-05T09:01:46.962539Z","shell.execute_reply.started":"2024-07-05T09:01:45.677121Z","shell.execute_reply":"2024-07-05T09:01:46.961026Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q aitextgen\n\nimport logging\nlogging.basicConfig(\n        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\n        level=logging.INFO\n    )\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:01:49.410387Z","iopub.execute_input":"2024-07-05T09:01:49.410896Z","iopub.status.idle":"2024-07-05T09:02:09.275749Z","shell.execute_reply.started":"2024-07-05T09:01:49.410865Z","shell.execute_reply":"2024-07-05T09:02:09.274709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install aitextgen\n!pip install accelerate -U\n!pip uninstall -y pytorch-lightning aitextgen\n!pip install pytorch-lightning==1.5.10\n!pip install aitextgen==0.5.2\n!pip install datasets\n!pip uninstall transformers -y\n!pip install transformers[torch]\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:02:09.277625Z","iopub.execute_input":"2024-07-05T09:02:09.277931Z","iopub.status.idle":"2024-07-05T09:03:59.906818Z","shell.execute_reply.started":"2024-07-05T09:02:09.277901Z","shell.execute_reply":"2024-07-05T09:03:59.905694Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: aitextgen in /opt/conda/lib/python3.10/site-packages (0.6.0)\nRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from aitextgen) (4.41.2)\nRequirement already satisfied: fire>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from aitextgen) (0.6.0)\nRequirement already satisfied: pytorch-lightning>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from aitextgen) (2.2.5)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from aitextgen) (2.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire>=0.3.0->aitextgen) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire>=0.3.0->aitextgen) (2.4.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (1.26.4)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (6.0.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (2024.3.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (1.4.0.post0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.7.0->aitextgen) (0.11.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen) (0.23.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen) (0.4.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.7.0->aitextgen) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning>=1.7.0->aitextgen) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->aitextgen) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->aitextgen) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.7.0->aitextgen) (4.0.3)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nCollecting accelerate\n  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\nSuccessfully installed accelerate-0.32.1\nFound existing installation: pytorch-lightning 2.2.5\nUninstalling pytorch-lightning-2.2.5:\n  Successfully uninstalled pytorch-lightning-2.2.5\nFound existing installation: aitextgen 0.6.0\nUninstalling aitextgen-0.6.0:\n  Successfully uninstalled aitextgen-0.6.0\nCollecting pytorch-lightning==1.5.10\n  Downloading pytorch_lightning-1.5.10-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (1.26.4)\nRequirement already satisfied: torch>=1.7.* in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (2.1.2)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (1.0.0)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (4.66.4)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (6.0.1)\nRequirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2024.3.1)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (2.15.1)\nRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (1.4.0.post0)\nCollecting pyDeprecate==0.3.1 (from pytorch-lightning==1.5.10)\n  Downloading pyDeprecate-0.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10) (4.9.0)\nCollecting setuptools==59.5.0 (from pytorch-lightning==1.5.10)\n  Downloading setuptools-59.5.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.9.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning==1.5.10) (3.1.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.59.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.32.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.1.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.5.10) (0.11.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.*->pytorch-lightning==1.5.10) (1.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.2.2)\nDownloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\nDownloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: setuptools, pyDeprecate, pytorch-lightning\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 69.0.3\n    Uninstalling setuptools-69.0.3:\n      Successfully uninstalled setuptools-69.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\narviz 0.18.0 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\nconda 24.5.0 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyDeprecate-0.3.1 pytorch-lightning-1.5.10 setuptools-59.5.0\nCollecting aitextgen==0.5.2\n  Downloading aitextgen-0.5.2.tar.gz (572 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.3/572.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from aitextgen==0.5.2) (4.41.2)\nRequirement already satisfied: fire>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from aitextgen==0.5.2) (0.6.0)\nRequirement already satisfied: pytorch-lightning>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from aitextgen==0.5.2) (1.5.10)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from aitextgen==0.5.2) (2.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire>=0.3.0->aitextgen==0.5.2) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire>=0.3.0->aitextgen==0.5.2) (2.4.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.26.4)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.0.0)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (4.66.4)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (6.0.1)\nRequirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (2024.3.1)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (2.15.1)\nRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.4.0.post0)\nRequirement already satisfied: pyDeprecate==0.3.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (0.3.1)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (4.9.0)\nRequirement already satisfied: setuptools==59.5.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=1.3.1->aitextgen==0.5.2) (59.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen==0.5.2) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen==0.5.2) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen==0.5.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->aitextgen==0.5.2) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen==0.5.2) (0.23.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen==0.5.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen==0.5.2) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen==0.5.2) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.5.1->aitextgen==0.5.2) (0.4.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.9.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.1.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.59.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen==0.5.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen==0.5.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen==0.5.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.5.1->aitextgen==0.5.2) (2024.2.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.4.1->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (0.11.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->aitextgen==0.5.2) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->aitextgen==0.5.2) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (1.3.1)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen==0.5.2) (3.2.2)\nBuilding wheels for collected packages: aitextgen\n  Building wheel for aitextgen (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575898 sha256=f2a9421febb77ad450071bf5d19d99e1e35f83e456414e8bac44bfdef30cc413\n  Stored in directory: /root/.cache/pip/wheels/20/11/6b/c2b02380a523b3373f3070da970d1fbffcb813238cc9570ed9\nSuccessfully built aitextgen\n\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: aitextgen\nSuccessfully installed aitextgen-0.5.2\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: transformers 4.41.2\nUninstalling transformers-4.41.2:\n  Successfully uninstalled transformers-4.41.2\nCollecting transformers[torch]\n  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m747.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.32.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nDownloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: transformers\nSuccessfully installed transformers-4.42.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from aitextgen import aitextgen\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:03:59.908310Z","iopub.execute_input":"2024-07-05T09:03:59.908692Z","iopub.status.idle":"2024-07-05T09:04:22.120954Z","shell.execute_reply.started":"2024-07-05T09:03:59.908651Z","shell.execute_reply":"2024-07-05T09:04:22.120190Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-07-05 09:04:11.249139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-05 09:04:11.249246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-05 09:04:11.429633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# use GPT Neo\nai = aitextgen(model=\"EleutherAI/gpt-neo-125M\", to_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:04:22.123406Z","iopub.execute_input":"2024-07-05T09:04:22.124073Z","iopub.status.idle":"2024-07-05T09:04:27.597106Z","shell.execute_reply.started":"2024-07-05T09:04:22.124038Z","shell.execute_reply":"2024-07-05T09:04:27.596270Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f2469717844c1fabc811094fa92394"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3856338cf34648359ce4127b1f82e5b1"}},"metadata":{}},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb87b288f7e4435b393b5e154bf39f5"}},"metadata":{}},{"name":"stderr","text":"loading configuration file generation_config.json from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2d9f66525b413e905da795e5ea498b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a16868f98de4f07a5a91c8ffcf4443c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bebf06b829294f1b802e5137fb61b590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecd2b61ecfb494397f1da7b361561bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b65339474c4fedadc4471a17a37b32"}},"metadata":{}},{"name":"stderr","text":"loading file vocab.json from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/vocab.json\nloading file merges.txt from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/merges.txt\nloading file tokenizer.json from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/special_tokens_map.json\nloading file tokenizer_config.json from cache at aitextgen/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport torch\n\n# Load the dataset\ndataset = load_dataset(\"codeparrot/xlcost-text-to-code\", \"C++-program-level\")\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Filter necessary columns\ntokenized_dataset = tokenized_dataset.remove_columns([\"text\", \"code\"])\n\n# Load the model\nmodel = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\")\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Set training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=1,  # Adjust batch size if necessary\n    num_train_epochs=2,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir=\"./logs\",\n)\n\n# Custom Trainer subclass\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs['input_ids']\n        outputs = model(**inputs)\n        logits = outputs.logits\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        loss_fct = torch.nn.CrossEntropyLoss()\n        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n        return (loss, outputs) if return_outputs else loss\n\n# Initialize CustomTrainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n)\n\n# Enable CUDA assertions\nimport os\nos.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n\n# Start training\ntrainer.train()\n\n# Save the trained model\nmodel.save_pretrained('./trained_model')\ntokenizer.save_pretrained('./trained_model')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:04:27.598379Z","iopub.execute_input":"2024-07-05T09:04:27.598726Z","iopub.status.idle":"2024-07-05T11:54:27.120552Z","shell.execute_reply.started":"2024-07-05T09:04:27.598697Z","shell.execute_reply":"2024-07-05T11:54:27.119474Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb88e887a20748b2abcdeba7dab15912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/379k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e4d6b72a4842b889ebaa42d4056108"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/210k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b8b57f33d8b45dc9c2b8492e7ebea4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9797 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6feea33196234dada2476c652b332abe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/909 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d4c8bda9c6045329d1e50a6c298b04b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/492 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8875156ac19a415aa0287b2338080c66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2761e0dba2415f968ab773e10b8c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147630d45c984ed89203857752a50076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d26f2dca09d49e38c141f25da1c3ef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a89216302c4d608ec60e847a1f0c4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32424c80b75d4ad3a1c018912abc2bbb"}},"metadata":{}},{"name":"stderr","text":"loading file vocab.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer_config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9797 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d861fe1b9cb46aaa675a7aa4d235691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/909 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f956851201d844688d80898e8a783947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/492 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa71c635c524f19ac1f937637c9f294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4c475463d34ffda3e82b2e5ce6847a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5462d1cd15e54ca3800826a1af1def6f"}},"metadata":{}},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbaa2beb5c4643db87567eb44158a4bb"}},"metadata":{}},{"name":"stderr","text":"loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n***** Running training *****\n  Num examples = 9,797\n  Num Epochs = 2\n  Instantaneous batch size per device = 1\n  Training with DataParallel so batch size has been adjusted to: 2\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 9,798\n  Number of trainable parameters = 125,199,360\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240705_090507-005c8o1d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface/runs/005c8o1d' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface' target=\"_blank\">https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface/runs/005c8o1d' target=\"_blank\">https://wandb.ai/nour-el-yakine-guendouz-ENSIA/huggingface/runs/005c8o1d</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9798' max='9798' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9798/9798 2:48:59, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>5.175700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>12.677100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>10.612800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.220300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.338900</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.291100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.272600</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.266100</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.252300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.234000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.238800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.238500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.232800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.219900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.218500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.213600</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.214100</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.216100</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.220100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./results/checkpoint-9798\nConfiguration saved in ./results/checkpoint-9798/generation_config.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nConfiguration saved in ./trained_model/generation_config.json\ntokenizer config file saved in ./trained_model/tokenizer_config.json\nSpecial tokens file saved in ./trained_model/special_tokens_map.json\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('./trained_model/tokenizer_config.json',\n './trained_model/special_tokens_map.json',\n './trained_model/vocab.json',\n './trained_model/merges.txt',\n './trained_model/added_tokens.json',\n './trained_model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(\"/kaggle/working/fine-tuned-gpt-neo-125M\")\ntokenizer.save_pretrained(\"/kaggle/working/fine-tuned-gpt-neo-125M\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:54:27.122221Z","iopub.execute_input":"2024-07-05T11:54:27.122645Z","iopub.status.idle":"2024-07-05T11:54:28.133743Z","shell.execute_reply.started":"2024-07-05T11:54:27.122607Z","shell.execute_reply":"2024-07-05T11:54:28.132771Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Configuration saved in /kaggle/working/fine-tuned-gpt-neo-125M/generation_config.json\ntokenizer config file saved in /kaggle/working/fine-tuned-gpt-neo-125M/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/fine-tuned-gpt-neo-125M/special_tokens_map.json\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine-tuned-gpt-neo-125M/tokenizer_config.json',\n '/kaggle/working/fine-tuned-gpt-neo-125M/special_tokens_map.json',\n '/kaggle/working/fine-tuned-gpt-neo-125M/vocab.json',\n '/kaggle/working/fine-tuned-gpt-neo-125M/merges.txt',\n '/kaggle/working/fine-tuned-gpt-neo-125M/added_tokens.json',\n '/kaggle/working/fine-tuned-gpt-neo-125M/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\n# Replace 'path_to_your_trained_model_directory' with the actual path\nmodel_path = '/kaggle/working/fine-tuned-gpt-neo-125M'\nmodel = AutoModelForCausalLM.from_pretrained(model_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:54:28.135042Z","iopub.execute_input":"2024-07-05T11:54:28.135399Z","iopub.status.idle":"2024-07-05T11:54:28.596293Z","shell.execute_reply.started":"2024-07-05T11:54:28.135363Z","shell.execute_reply":"2024-07-05T11:54:28.595461Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\nloading configuration file /kaggle/working/fine-tuned-gpt-neo-125M/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n\n# Example input text\ninput_text = \"C++ code to generate random numbers\"\n\n# Tokenize input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:58:55.570828Z","iopub.execute_input":"2024-07-05T11:58:55.571245Z","iopub.status.idle":"2024-07-05T11:58:55.839022Z","shell.execute_reply.started":"2024-07-05T11:58:55.571212Z","shell.execute_reply":"2024-07-05T11:58:55.837917Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"loading file vocab.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neo-125M/snapshots/21def0189f5705e2521767faed922f1f15e7d7db/tokenizer_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Generate text\noutput = model.generate(\n    inputs.input_ids,\n    attention_mask=inputs.attention_mask,  # Include attention mask\n    max_length=1000,\n    num_return_sequences=1,\n    no_repeat_ngram_size=2,\n    early_stopping=True,\n    temperature=0.7,\n    top_k=50,\n    top_p=0.9,\n    pad_token_id=tokenizer.pad_token_id,\n    bos_token_id=tokenizer.bos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\n\n# Decode generated output tokens back to text\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"Generated Text:\")\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:00:57.242255Z","iopub.execute_input":"2024-07-05T12:00:57.242954Z","iopub.status.idle":"2024-07-05T12:01:01.670644Z","shell.execute_reply.started":"2024-07-05T12:00:57.242917Z","shell.execute_reply":"2024-07-05T12:01:01.669463Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Text:\nC++ code to generate random numbers.\n\nA:\n#include <iostream>\nusing namespace std;\nint main()\n{\n   int n = 100;\n\n  cout << \"Enter a random number: \"; \n}\nvoid random() {\ncin >> n; //random number\ncout << endl;//random\nn = 0;cOut << n <<endl\nfor (int i = 1; i < n-1; ++i)\n {  //do something\n }\n cout. coutback();\n return 0 ;\n};\n//main()\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}